{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "uBRK9o7bQjV8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import zscore\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Graphiques\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as gp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Statistiques\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.cluster import KMeans\n",
        "import sklearn.preprocessing as preproc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "zaI5d1O0YKUa"
      },
      "outputs": [],
      "source": [
        "input_path = \"./01_Input_Data\"\n",
        "output_path = \"./2_outputs\"\n",
        "df = pd.read_csv(input_path + '/bank-additional-full.csv', delimiter = ';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw2DWOauhWZV"
      },
      "source": [
        "# Visualisation des données\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_-XbU7dfYQgP",
        "outputId": "8961482b-5c3d-4dbd-dc96-9063478ddd5f"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLrnDlDKYSyY",
        "outputId": "7f8e41e4-d5dd-4930-d4db-8fa123b1027c"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Zyj7pN9HYTtX",
        "outputId": "0a686def-c2e7-45c6-ec3f-e8694bf840e4"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkwY0E77ZDVU",
        "outputId": "f97736ac-928c-443c-8fd0-c4e5b1d25096"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "GWlgQQMBYgsd"
      },
      "outputs": [],
      "source": [
        "def afficher_distribution(df, colonne):\n",
        "    # Création de la figure et des sous-graphiques\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Tracer l'histogramme avec la courbe de densité\n",
        "    sns.histplot(df[colonne], kde=True, bins=25, stat='density', linewidth=0, ax=ax)\n",
        "\n",
        "    # Titre et labels\n",
        "    ax.set_title(f'Distribution de la variable: {colonne}', fontsize=15)\n",
        "    ax.set_xlabel(colonne, fontsize=12)\n",
        "    ax.set_ylabel('Densité', fontsize=12)\n",
        "\n",
        "    # Calcul des statistiques descriptives\n",
        "    stats = df[colonne].describe()\n",
        "\n",
        "    # Texte contenant les statistiques descriptives\n",
        "    stats_text = \"\\n\".join([f\"{key}: {value:.2f}\" for key, value in stats.items()])\n",
        "\n",
        "    # Ajouter le texte à côté du graphique\n",
        "    plt.gcf().text(0.75, 0.5, stats_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    # Afficher le graphique\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def afficher_distribution_categorielle(df, colonne):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    sns.countplot(data=df, x=colonne)\n",
        "\n",
        "    plt.title(f'Distribution des catégories de : {colonne}', fontsize=15)\n",
        "    plt.xlabel(colonne, fontsize=12)\n",
        "    plt.ylabel('Nombre d\\'occurrences', fontsize=12)\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "0KpSi_BMbovg",
        "outputId": "cb0e09c1-7a5a-4db4-e82c-01a18c97e08f"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'age')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "ujOqbj5MbrgC",
        "outputId": "e916012b-519a-4048-a0ef-4f57af331bee"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'job')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "I5FixbGecOAR",
        "outputId": "28660eaa-dd18-49db-9529-7314efa828ad"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'marital')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "IDKdvwDid5m_",
        "outputId": "e08cae0d-bf62-4fcb-84f9-212c4469381b"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'education')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "D1FhLWL8d-GC",
        "outputId": "d8df382a-0fdb-457f-92b2-39ad69805ee0"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'default')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "XAxClaaseGg0",
        "outputId": "ac1794ff-cf77-4e47-bdd1-7889021330c3"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'housing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "6_c1UEBXeKxO",
        "outputId": "7c7c5d57-b291-4e81-a108-6355ac451b3b"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'loan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "_zfTjMGBeMlW",
        "outputId": "1c120aad-1e8f-4c70-ee71-8df906387755"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'contact')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "X79S4uiweRip",
        "outputId": "22e8c0d1-3492-4ca9-febe-326119f00176"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'month')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "l8pcDRX5eU4u",
        "outputId": "db72f885-0a9c-48d3-e168-38e1da724ab7"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'day_of_week')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "LifJILtsexnA",
        "outputId": "c409a14a-379b-444b-db32-e06108773606"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "PooypL2xe4AR",
        "outputId": "92a5e1fc-0af7-4fdc-cc33-8bda57f3dc41"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'campaign')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "9zgKGe_7fJey",
        "outputId": "d0ae39a4-8948-4666-a490-e8f1e5ccbd65"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'pdays')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "jqj8jkMnfa3E",
        "outputId": "4c25996b-57f4-48de-a5e2-c28625e1ae7c"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'previous')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "CgcVvGkyfpgs",
        "outputId": "019e5601-84d2-4601-def2-c832b41c3106"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'poutcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "BN58CT0Hf4tI",
        "outputId": "fb8e0737-4307-4f35-bb44-8029c370378e"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'emp.var.rate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "0lr3Mgpsf-ML",
        "outputId": "c7e6397e-8ce3-434d-9981-84c3253cd675"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'cons.price.idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "n0G6tMfvg7lu",
        "outputId": "4d7b00bf-41b2-4974-b2bc-17dc1c9c02ed"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'cons.conf.idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "D0yRvKkHg_cs",
        "outputId": "53af42c9-bc04-4bb8-d1e8-c0436e5ef616"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'euribor3m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "TL2Tvu1OhDnN",
        "outputId": "f1df77a1-5ab5-4eb4-87e3-4595c6e63804"
      },
      "outputs": [],
      "source": [
        "afficher_distribution(df, 'nr.employed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "94sDei40hIE7",
        "outputId": "6bda2c28-e9f4-43fa-8690-c4f84de15297"
      },
      "outputs": [],
      "source": [
        "afficher_distribution_categorielle(df, 'y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "JZ0W2bH0p8L8"
      },
      "outputs": [],
      "source": [
        "def plot_numeric_correlation(df):\n",
        "    \"\"\"\n",
        "    Cette fonction affiche une matrice de corrélation pour les variables numériques d'un DataFrame.\n",
        "    \"\"\"\n",
        "    # Sélectionner uniquement les colonnes numériques\n",
        "    numeric_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "    # Calcul de la matrice de corrélation\n",
        "    corr_matrix = numeric_df.corr()\n",
        "\n",
        "    # Affichage de la matrice de corrélation sous forme de carte thermique\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title(\"Matrice de Corrélation des Variables Numériques\")\n",
        "    plt.show()\n",
        "\n",
        "def cramers_v(x, y):\n",
        "    \"\"\"\n",
        "    Calcul du V de Cramér pour mesurer l'association entre deux variables catégorielles.\n",
        "    \"\"\"\n",
        "    # Créer une table de contingence entre les deux variables\n",
        "    contingency_table = pd.crosstab(x, y)\n",
        "\n",
        "    # Effectuer le test du chi carré\n",
        "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "    # Calcul du V de Cramér\n",
        "    n = contingency_table.sum().sum()  # Taille totale de l'échantillon\n",
        "    min_dim = min(contingency_table.shape) - 1  # Minimum entre (k1-1) et (k2-1)\n",
        "    v_cramer = np.sqrt(chi2 / (n * min_dim))\n",
        "\n",
        "    return v_cramer\n",
        "\n",
        "def plot_categorical_association(df):\n",
        "    \"\"\"\n",
        "    Cette fonction affiche une matrice d'association (V de Cramér) pour les variables catégorielles d'un DataFrame.\n",
        "    \"\"\"\n",
        "    # Sélectionner uniquement les colonnes catégorielles\n",
        "    categorical_df = df.select_dtypes(include=['object', 'category'])\n",
        "\n",
        "    # Initialiser une matrice vide pour les résultats de V de Cramér\n",
        "    v_matrix = pd.DataFrame(index=categorical_df.columns, columns=categorical_df.columns)\n",
        "\n",
        "    # Calculer les valeurs de V de Cramér pour chaque paire de variables\n",
        "    for col1 in categorical_df.columns:\n",
        "        for col2 in categorical_df.columns:\n",
        "            v_matrix.loc[col1, col2] = cramers_v(categorical_df[col1], categorical_df[col2])\n",
        "\n",
        "    # Affichage de la matrice d'association sous forme de carte thermique\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(v_matrix.astype(float), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title(\"Matrice d'Association des Variables Catégorielles (V de Cramér)\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "aH6TVjLcqAS6",
        "outputId": "98d72cce-4bba-412a-c70f-539c0555ce79"
      },
      "outputs": [],
      "source": [
        "plot_numeric_correlation(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "ZrpPrvMVrHL3",
        "outputId": "cb902b53-d16c-4ee3-ded5-0f6a765981fd"
      },
      "outputs": [],
      "source": [
        "plot_categorical_association(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQx1nDLdkkKh"
      },
      "source": [
        "# Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "uw5soczqhLOr"
      },
      "outputs": [],
      "source": [
        "df.drop(columns =['duration'], inplace = True, errors = \"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "xC8Wj7lpwHJL"
      },
      "outputs": [],
      "source": [
        "def apply_pca(df, features, n_components=1):\n",
        "    # Extraire les variables d'intérêt\n",
        "    X = df[features]\n",
        "\n",
        "    # Standardiser les données\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Appliquer l'ACP'\n",
        "    pca = PCA(n_components=n_components)\n",
        "    df['PC'] = pca.fit_transform(X_scaled).flatten()\n",
        "\n",
        "    # Supprimer les variables d'origine\n",
        "    df.drop(columns=features, inplace=True, errors='ignore')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ_yXI3dsDGy",
        "outputId": "6417ac7c-cb53-49ea-8a7c-6bea7630bc58"
      },
      "outputs": [],
      "source": [
        "df.drop(columns = ['default'], inplace = True, errors = \"ignore\")\n",
        "\n",
        "df.drop(columns = ['pdays'], inplace = True, errors = \"ignore\")\n",
        "\n",
        "\n",
        "features = [\"euribor3m\", \"emp.var.rate\", \"nr.employed\"]\n",
        "\n",
        "df = apply_pca(df, features, n_components=1)\n",
        "\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "z_scores = numerical_df.apply(zscore)\n",
        "\n",
        "# Ligne avec une colonne avec z-score > 3\n",
        "outlier_rows = df[(np.abs(z_scores) > 3).any(axis=1)]\n",
        "\n",
        "print(outlier_rows)\n",
        "\n",
        "df = df.drop(outlier_rows.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tq7LmVUq9p5_",
        "outputId": "a77e4a8f-3587-4045-c5b7-ede0929fcfde"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOTP1FdYJCnX"
      },
      "source": [
        "# ICI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "vHn1Kr3uKiah"
      },
      "outputs": [],
      "source": [
        "\n",
        "def classifier_variables(data_set):\n",
        "    # Initialisation des listes\n",
        "    variables_na = []\n",
        "    variables_numeriques = []\n",
        "    variables_01 = []\n",
        "    variables_categorielles = []\n",
        "\n",
        "    # Parcourir les colonnes du dataset\n",
        "    for colu in data_set.columns:\n",
        "        # Vérifier si la colonne contient des valeurs NaN\n",
        "        if data_set[colu].isna().any():\n",
        "            variables_na.append(colu)\n",
        "        else:\n",
        "            # Vérifier si la colonne est de type numérique\n",
        "            if data_set[colu].dtype in [\"int32\", \"int64\", \"float32\", \"float64\"]:\n",
        "                # Vérifier si la colonne est binaire (deux valeurs uniques)\n",
        "                if len(data_set[colu].unique()) == 2:\n",
        "                    variables_01.append(colu)\n",
        "                else:\n",
        "                    variables_numeriques.append(colu)\n",
        "            else:\n",
        "                # Gérer les colonnes non numériques\n",
        "                if len(data_set[colu].unique()) == 2:\n",
        "                    variables_01.append(colu)\n",
        "                else:\n",
        "                    variables_categorielles.append(colu)\n",
        "\n",
        "    # Création du dictionnaire des résultats\n",
        "    resultat = {\n",
        "        \"variables_na\": variables_na,\n",
        "        \"variables_numeriques\": variables_numeriques,\n",
        "        \"variables_binaires\": variables_01,\n",
        "        \"variables_categorielles\": variables_categorielles\n",
        "    }\n",
        "\n",
        "    return resultat\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# variables= classifier_variables(data_set)\n",
        "# print(variables)\n",
        "# data_set.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "TbHUW7IuKDac"
      },
      "outputs": [],
      "source": [
        "\n",
        "def encoded_categorial(data):\n",
        "    \"\"\"\n",
        "    Effectue le one-hot encoding sur les variables catégoriques.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Le DataFrame contenant les données à traiter.\n",
        "        variables (dict): Dictionnaire contenant les listes de colonnes sous les clés :\n",
        "                          - 'variables_categorielles' : liste des colonnes catégoriques.\n",
        "                          - 'variables_binaires' : liste des colonnes binaires.\n",
        "                          - 'variables_numeriques' : liste des colonnes numériques.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Un DataFrame avec les variables catégoriques encodées,\n",
        "                      et les autres colonnes inchangées.\n",
        "    \"\"\"\n",
        "    # Récupérer les variables catégoriques, binaires et numériques\n",
        "    variables= classifier_variables(data)\n",
        "    variables_categorielles = variables.get(\"variables_categorielles\", [])\n",
        "    variables_binaires = variables.get(\"variables_binaires\", [])\n",
        "    variables_numeriques = variables.get(\"variables_numeriques\", [])\n",
        "\n",
        "\n",
        "    # Sélectionner uniquement les colonnes catégoriques et binaires\n",
        "    data_categorielles = data[variables_categorielles+variables_binaires]\n",
        "\n",
        "    # Initialiser l'encodeur pour les variables catégoriques\n",
        "    preproc_ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "    # Ajuster et transformer les variables catégoriques\n",
        "    preproc_ohe.fit(data_categorielles)\n",
        "    variables_categorielles_ohe = preproc_ohe.transform(data_categorielles)\n",
        "\n",
        "    # Convertir le résultat en DataFrame\n",
        "    variables_categorielles_ohe = pd.DataFrame(\n",
        "        variables_categorielles_ohe,\n",
        "        columns=preproc_ohe.get_feature_names_out(data_categorielles.columns),\n",
        "        index=data.index  # Conserver les index originaux\n",
        "    )\n",
        "\n",
        "    if variables_numeriques:\n",
        "        data_numeriques = data[variables_numeriques]\n",
        "        data_numeriques= pd.DataFrame(\n",
        "            data_numeriques,\n",
        "            columns=variables_numeriques,\n",
        "            index=data.index\n",
        "        )\n",
        "    else:\n",
        "        data_numeriques = pd.DataFrame(index=data.index)\n",
        "\n",
        "    # Supprimer les colonnes catégorielles et binaires d'origine et ajouter les colonnes encodées\n",
        "    data_final = pd.concat([\n",
        "        variables_categorielles_ohe,\n",
        "        data_numeriques\n",
        "    ], axis=1)\n",
        "\n",
        "    return data_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import pandas as pd\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import ADASYN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Encodage des variables catégorielles\n",
        "y = df['y']\n",
        "X = pd.get_dummies(df.drop('y', axis=1), drop_first=True)\n",
        "\n",
        "# Séparation des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
        "\n",
        "# Suréchantillonnage des données d'entraînement\n",
        "sampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# smote_tomek = SMOTETomek(random_state=42)\n",
        "# X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# Standardisation des données\n",
        "scaler = StandardScaler()\n",
        "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fitting avec cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23igMIT1H2NO",
        "outputId": "69ec3aa4-535b-49e3-9964-77c99a6fc613"
      },
      "outputs": [],
      "source": [
        "# Recherche des hyperparamètres avec GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 2, 4,6],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "num_folds = 3\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='precision',  # Métrique pour maximiser l'AUC-ROC\n",
        "    cv=KFold(n_splits=num_folds, shuffle=True, random_state=42),\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialisation du modèle Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Prédictions initiales\n",
        "y_pred = rf_model.predict(X_test)\n",
        "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Évaluation initiale\n",
        "print(\"\\n### Matrice de confusion ###\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n### Rapport de classification ###\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n### Score AUC-ROC ###\")\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "print(f\"AUC-ROC: {auc_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ajustement avec GridSearch\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Résultats de la recherche d'hyperparamètres\n",
        "print(\"\\n### Meilleurs paramètres ###\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Utilisation du meilleur modèle\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Prédictions finales\n",
        "final_y_pred = best_rf_model.predict(X_test)\n",
        "final_y_proba = best_rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Rapport final\n",
        "print(\"\\n### Rapport final de classification ###\")\n",
        "print(classification_report(y_test, final_y_pred))\n",
        "\n",
        "print(\"\\n### Score AUC-ROC final ###\")\n",
        "final_auc_score = roc_auc_score(y_test, final_y_proba)\n",
        "print(f\"AUC-ROC final: {final_auc_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# Étape 1 : Encodage des variables catégorielles\n",
        "y = df['y'].map({'no': 0, 'yes': 1})\n",
        "X = pd.get_dummies(df.drop('y', axis=1), drop_first=True)\n",
        "\n",
        "# Étape 2 : Séparation Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Étape 3 : Suréchantillonnage avec SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Étape 4 : Standardisation des données\n",
        "scaler = StandardScaler()\n",
        "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Étape 5 : Initialisation du modèle Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Étape 6 : Entraînement initial sans ajustement d'hyperparamètres\n",
        "gb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Prédictions initiales\n",
        "y_pred = gb_model.predict(X_test)\n",
        "y_proba = gb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Évaluation initiale\n",
        "print(\"\\n### Matrice de confusion ###\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n### Rapport de classification ###\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n### Score AUC-ROC ###\")\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "print(f\"AUC-ROC: {auc_score:.4f}\")\n",
        "\n",
        "# Étape 7 : Recherche d'hyperparamètres avec GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=KFold(n_splits=num_folds, shuffle=True, random_state=42),\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Ajustement avec GridSearch\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Résultats de la recherche d'hyperparamètres\n",
        "print(\"\\n### Meilleurs paramètres ###\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Étape 8 : Utilisation du meilleur modèle\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Prédictions finales\n",
        "final_y_pred = best_gb_model.predict(X_test)\n",
        "final_y_proba = best_gb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Rapport final\n",
        "print(\"\\n### Rapport final de classification ###\")\n",
        "print(classification_report(y_test, final_y_pred))\n",
        "\n",
        "print(\"\\n### Score AUC-ROC final ###\")\n",
        "final_auc_score = roc_auc_score(y_test, final_y_proba)\n",
        "print(f\"AUC-ROC final: {final_auc_score:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "usr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
